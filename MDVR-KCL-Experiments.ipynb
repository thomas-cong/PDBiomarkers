{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ead5d8d",
   "metadata": {},
   "source": [
    "**Dataset:** [zenodo.org/records/2867216](https://zenodo.org/records/2867216)\n",
    "**Validation Code:**  [github.com/aeesha-T/parkinsons_prediction_using_speech](https://github.com/aeesha-T/parkinsons_prediction_using_speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3399d970",
   "metadata": {},
   "outputs": [],
   "source": [
    "import feature_calculation.build_biomarker_csv as build_biomarker_csv\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['savefig.dpi'] = 300\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5472e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the csv files\n",
    "build_biomarker_csv.build_csv(\"./MDVR-KCL-Features/MDVR-KCL-ReadTextPD-Eng.csv\", audio_dir=\"./MDVR-KCL/ReadText/PD-Eng\")\n",
    "build_biomarker_csv.build_csv(\"./MDVR-KCL-Features/MDVR-KCL-ReadTextHC-Eng.csv\", audio_dir=\"./MDVR-KCL/ReadText/HC-Eng\")\n",
    "build_biomarker_csv.build_csv(\"./MDVR-KCL-Features/MDVR-KCL-ReadTextPD-Sun.csv\", audio_dir=\"./MDVR-KCL/ReadText/PD-Sun\")\n",
    "build_biomarker_csv.build_csv(\"./MDVR-KCL-Features/MDVR-KCL-ReadTextHC-Sun.csv\", audio_dir=\"./MDVR-KCL/ReadText/HC-Sun\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c69fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data/sorted\n",
    "pd_eng = pd.read_csv(\"./MDVR-KCL-Features/MDVR-KCL-ReadTextPD-Eng.csv\", index_col=\"filename\").sort_index()\n",
    "hc_eng = pd.read_csv(\"./MDVR-KCL-Features/MDVR-KCL-ReadTextHC-Eng.csv\", index_col=\"filename\").sort_index()\n",
    "pd_sun = pd.read_csv(\"./MDVR-KCL-Features/MDVR-KCL-ReadTextPD-Sun.csv\", index_col=\"filename\").sort_index()\n",
    "hc_sun = pd.read_csv(\"./MDVR-KCL-Features/MDVR-KCL-ReadTextHC-Sun.csv\", index_col=\"filename\").sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba385dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acoustic features generated per (https://arxiv.org/abs/2111.10207) on MVDR\n",
    "full_validation_set = pd.read_csv(\"./Validation Files/MDVR_KCL_reading_acoustic_features.csv\")\n",
    "pd_eng_validation = full_validation_set[full_validation_set[\"voiceID\"].str.contains(\"PD-Eng\") & full_validation_set[\"voiceID\"].str.contains(\"preprocessed\")]\n",
    "hc_eng_validation = full_validation_set[full_validation_set[\"voiceID\"].str.contains(\"HC-Eng\") & full_validation_set[\"voiceID\"].str.contains(\"preprocessed\")]\n",
    "pd_sun_validation = full_validation_set[full_validation_set[\"voiceID\"].str.contains(\"PD-Sun\") & full_validation_set[\"voiceID\"].str.contains(\"preprocessed\")]\n",
    "hc_sun_validation = full_validation_set[full_validation_set[\"voiceID\"].str.contains(\"HC-Sun\") & full_validation_set[\"voiceID\"].str.contains(\"preprocessed\")]\n",
    "# Rename columns properly to match the sets of features\n",
    "renaming = {\n",
    "    \"meanF0Hz\": \"ff_mean\",\n",
    "    \"stdevF0Hz\": \"ff_std\",\n",
    "    \"HNR\": \"harm_mean\",\n",
    "    \"localJitter\": \"jitter_local\",\n",
    "    \"localabsoluteJitter\": \"jitter_local_db\",\n",
    "    \"rapJitter\": \"jitter_rap\",\n",
    "    \"ppq5Jitter\": \"jitter_ppq5\",\n",
    "    \"localShimmer\": \"shimmer_local\",\n",
    "    \"localdbShimmer\": \"shimmer_local_db\",\n",
    "    \"apq3Shimmer\": \"shimmer_apq3\",\n",
    "    \"apq5Shimmer\": \"shimmer_apq5\",\n",
    "\n",
    "}\n",
    "# Reformat columns and sort both dataframes to be same order\n",
    "for df in [pd_eng_validation, hc_eng_validation, pd_sun_validation, hc_sun_validation]:\n",
    "    df[\"voiceID\"] = df[\"voiceID\"].str.split(\"/\").str[-1].str.replace(\"_preprocessed\", \"\").str.replace(\".wav\", \"\")\n",
    "    df.set_index(\"voiceID\", inplace=True)\n",
    "    df.sort_index(inplace=True)\n",
    "    df.rename(columns=renaming, inplace=True)\n",
    "    df.drop(columns=df.columns.difference([\"ff_mean\", \"ff_std\", \"harm_mean\", \"jitter_local\", \"jitter_local_db\", \"jitter_rap\", \"jitter_ppq5\", \"shimmer_local\", \"shimmer_local_db\", \"shimmer_apq3\", \"shimmer_apq5\"]), inplace=True)\n",
    "for df in [pd_eng, hc_eng, pd_sun, hc_sun]:\n",
    "    df.drop(columns=df.columns.difference([\"ff_mean\", \"ff_std\", \"harm_mean\", \"jitter_local\", \"jitter_local_db\", \"jitter_rap\", \"jitter_ppq5\", \"shimmer_local\", \"shimmer_local_db\", \"shimmer_apq3\", \"shimmer_apq5\"]), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89924c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "triples = [(pd_eng, pd_eng_validation, 'PD Engineering'), \n",
    "         (hc_eng, hc_eng_validation, 'HC Engineering'), \n",
    "         (pd_sun, pd_sun_validation, 'PD Sun Story'), \n",
    "         (hc_sun, hc_sun_validation, 'HC Sun Story')]\n",
    "def plot_validation_metrics(test, validation, title):\n",
    "    # Create a figure with subplots\n",
    "    f, axs = plt.subplots(len(test.columns), 1, figsize=(8, 16))\n",
    "    # Iterate over each column and create a strip plot\n",
    "    for i, col in enumerate(test.columns):\n",
    "        upper_lim = max(test[col].max(), validation[col].max()) * 1.1\n",
    "        lower_lim = min(test[col].min(), validation[col].min()) * 0.9\n",
    "        # Plot validation data\n",
    "        sns.stripplot(data=validation, x=validation.index.str.split('_').str[0], y=col, ax=axs[i], color='green')\n",
    "        # Plot test data\n",
    "        sns.stripplot(data=test, x=test.index.str.split('_').str[0], y=col, ax=axs[i], color='blue', alpha=0.6)\n",
    "        # Remove x-labels for all but the last subplot\n",
    "        if i != len(test.columns) - 1:\n",
    "            axs[i].set_xlabel('')\n",
    "            axs[i].set(xticks=[])\n",
    "        else:\n",
    "            axs[i].set_xlabel(\"Sample ID\")\n",
    "        axs[i].set_ylim(lower_lim, upper_lim)\n",
    "\n",
    "    # Create custom legend handles\n",
    "    blue_patch = mpatches.Patch(color='blue', label='Test')\n",
    "    green_patch = mpatches.Patch(color='green', label='Validation')\n",
    "\n",
    "    # Add legend to the right\n",
    "    f.legend(handles=[green_patch, blue_patch], \n",
    "         loc='center left', \n",
    "         bbox_to_anchor=(0.9, 0.5),  # Move legend closer to the right\n",
    "         title='Legend')\n",
    "\n",
    "    # Move the suptitle up to create margin above the first plot\n",
    "    f.suptitle(title, y = 0.89)  # y > 1 moves the title up\n",
    "\n",
    "    f.tight_layout(rect=[0, 0, 0.88, 0.9])  # Leave space at top for title, right for legend\n",
    "    f.savefig(f\"./Validation Files/Plots/MDVR-KCL_{title}_validation.png\", bbox_inches='tight', dpi=300)\n",
    "    return f\n",
    "for triple in triples:\n",
    "    plot = plot_validation_metrics(triple[0], triple[1], triple[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f64e567",
   "metadata": {},
   "source": [
    "**Data Exploration Experiments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2ac170",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf4618d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data/sorted\n",
    "MDVR_pd_eng = pd.read_csv(\"./MDVR-KCL-Features/MDVR-KCL-ReadTextPD-Eng.csv\", index_col=\"filename\").sort_index()\n",
    "MDVR_pd_sun = pd.read_csv(\"./MDVR-KCL-Features/MDVR-KCL-ReadTextPD-Sun.csv\", index_col=\"filename\").sort_index()\n",
    "MDVR_hc_eng = pd.read_csv(\"./MDVR-KCL-Features/MDVR-KCL-ReadTextHC-Eng.csv\", index_col=\"filename\").sort_index()\n",
    "MDVR_hc_sun = pd.read_csv(\"./MDVR-KCL-Features/MDVR-KCL-ReadTextHC-Sun.csv\", index_col=\"filename\").sort_index()\n",
    "df_list = [MDVR_pd_eng, MDVR_pd_sun, MDVR_hc_eng, MDVR_hc_sun]\n",
    "merged_df = pd.concat(df_list)\n",
    "merged_df.to_csv(\"./MDVR-KCL-Features/MDVR-KCL-ReadText.csv\")\n",
    "pd_only = pd.concat([MDVR_pd_eng, MDVR_pd_sun])\n",
    "hc_only = pd.concat([MDVR_hc_eng, MDVR_hc_sun])\n",
    "pd_only.to_csv(\"./MDVR-KCL-Features/MDVR-KCL-ReadTextPD.csv\")\n",
    "hc_only.to_csv(\"./MDVR-KCL-Features/MDVR-KCL-ReadTextHC.csv\")\n",
    "eng_only = pd.concat([MDVR_pd_eng, MDVR_hc_eng])\n",
    "sun_only = pd.concat([MDVR_pd_sun, MDVR_hc_sun])\n",
    "eng_only.to_csv(\"./MDVR-KCL-Features/MDVR-KCL-ReadTextEng.csv\")\n",
    "sun_only.to_csv(\"./MDVR-KCL-Features/MDVR-KCL-ReadTextSun.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8434ebd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"SUN-ONLY\"\n",
    "\n",
    "normalize_merged = sun_only.copy()\n",
    "\n",
    "PD_array = [True if \"pd\" in x else False for x in normalize_merged.index]\n",
    "\n",
    "for col in normalize_merged.columns:\n",
    "    normalize_merged[col] = (normalize_merged[col] - normalize_merged[col].mean()) / normalize_merged[col].std()\n",
    "pca = PCA()\n",
    "pca.fit(normalize_merged)\n",
    "data = pca.transform(normalize_merged)\n",
    "explained_var = pca.explained_variance_ratio_\n",
    "cumulative_var = np.cumsum(explained_var)\n",
    "\n",
    "\n",
    "f, ax = plt.subplots(figsize=(10,6))\n",
    "sns.barplot(cumulative_var, ax=ax)\n",
    "ax.set_title(\"Cumulative Explained Variance\")\n",
    "ax.set_yticks(np.arange(0,1.1,0.1))\n",
    "ax.set_xlabel(\"Components\")\n",
    "ax.set_ylabel(\"% Variance\")\n",
    "ax.tick_params(axis='both', labelsize=6)\n",
    "\n",
    "square_size = 5\n",
    "param = \"aavs\"\n",
    "pca_f, pca_ax = plt.subplots(square_size,square_size,figsize=(12,6))\n",
    "pca_f.subplots_adjust(wspace=0.4, hspace=0.6)\n",
    "norm = mpl.colors.Normalize(vmin=normalize_merged[param].min(), vmax=normalize_merged[param].max())\n",
    "cmap = mpl.cm.viridis\n",
    "def plot_pca(i, j, ax):\n",
    "    if i == j:\n",
    "        ax.set_facecolor('white')\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        for spine in ax.spines.values():\n",
    "            spine.set_visible(False)\n",
    "        if i == 0:\n",
    "            ax.set_xlabel(f\"PC{j+1}\", fontsize=8)\n",
    "            ax.xaxis.set_label_position(\"top\")\n",
    "        if j == 0:\n",
    "            ax.set_ylabel(f\"PC{i+1}\", fontsize=8)\n",
    "        return\n",
    "    if i == 0:\n",
    "        ax.set_xlabel(f\"PC{j+1}\", fontsize=8)\n",
    "        ax.xaxis.set_label_position(\"top\")\n",
    "    if j == 0:\n",
    "        ax.set_ylabel(f\"PC{i+1}\", fontsize=8)\n",
    "    ax.tick_params(axis='both', labelsize=6)\n",
    "    \n",
    "    # Split data by PD status\n",
    "    pd_mask = np.array(PD_array)\n",
    "    ctrl_mask = ~pd_mask\n",
    "\n",
    "    # Plot PD (e.g. circles)\n",
    "    sns.scatterplot(\n",
    "        x=data[pd_mask, j], y=data[pd_mask, i],\n",
    "        ax=ax, c=normalize_merged.iloc[pd_mask][param], cmap=cmap, s=8, norm=norm,\n",
    "        marker='X', label='PD', legend=False\n",
    "    )\n",
    "    # Plot Control (e.g. squares)\n",
    "    sns.scatterplot(\n",
    "        x=data[ctrl_mask, j], y=data[ctrl_mask, i],\n",
    "        ax=ax, c=normalize_merged.iloc[ctrl_mask][param], cmap=cmap, s=8, norm=norm,\n",
    "        marker='o', label='Control', legend=False\n",
    "    )\n",
    "sm = mpl.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])\n",
    "pca_f.colorbar(sm, ax=pca_ax, orientation='vertical', fraction=0.02, label= param + \"(std)\", anchor=(2.1, 0.5))\n",
    "for i in range(square_size):      # i: row index, PC on y-axis (PCi+1)\n",
    "    for j in range(square_size):  # j: col index, PC on x-axis (PCj+1)\n",
    "        plot_pca(i, j, pca_ax[i,j])\n",
    "        # Store handles and labels from the first subplot that has both groups\n",
    "for i in range(square_size):\n",
    "    for j in range(square_size):\n",
    "        if i != j:\n",
    "            handles, labels = pca_ax[i, j].get_legend_handles_labels()\n",
    "            if handles:\n",
    "                break\n",
    "    if handles:\n",
    "        break\n",
    "\n",
    "# Add a single legend to the figure\n",
    "pca_f.legend(\n",
    "    handles, labels,\n",
    "    loc='upper right',\n",
    "    bbox_to_anchor=(1.15, 1),\n",
    "    scatterpoints=1,        # Number of marker points in the legend entry\n",
    "    markerscale=2,          # Scale factor for legend markers (increase for bigger points)\n",
    "    fontsize=10             # Legend text size\n",
    ")\n",
    "pca_f.align_ylabels([pca_ax[:,0]])\n",
    "\n",
    "    \n",
    "pca_f.savefig(f'./Plots/{square_size}x{square_size}_{param}_pca_{dataset}.png')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90449ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "square_size = 5\n",
    "kernel = \"poly\"\n",
    "\n",
    "kernel_pca = KernelPCA(kernel=kernel)\n",
    "kernel_pca.fit(normalize_merged)\n",
    "data = kernel_pca.transform(normalize_merged)\n",
    "\n",
    "\n",
    "kpca_f, kpca_ax = plt.subplots(square_size,square_size,figsize=(12,6))\n",
    "kpca_f.subplots_adjust(wspace=0.4, hspace=0.6)\n",
    "norm = mpl.colors.Normalize(vmin=normalize_merged[param].min(), vmax=normalize_merged[param].max())\n",
    "cmap = mpl.cm.viridis\n",
    "\n",
    "sm = mpl.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])\n",
    "kpca_f.colorbar(sm, ax=kpca_ax, orientation='vertical', fraction=0.02, label= param + \"(std)\", anchor=(2.1, 0.5))\n",
    "for i in range(square_size):      # i: row index, PC on y-axis (PCi+1)\n",
    "    for j in range(square_size):  # j: col index, PC on x-axis (PCj+1)\n",
    "        plot_pca(i, j, kpca_ax[i,j])\n",
    "        # Store handles and labels from the first subplot that has both groups\n",
    "for i in range(square_size):\n",
    "    for j in range(square_size):\n",
    "        if i != j:\n",
    "            handles, labels = kpca_ax[i, j].get_legend_handles_labels()\n",
    "            if handles:\n",
    "                break   \n",
    "    if handles:\n",
    "        break\n",
    "\n",
    "# Add a single legend to the figure\n",
    "kpca_f.legend(\n",
    "    handles, labels,\n",
    "    loc='upper right',\n",
    "    bbox_to_anchor=(1.15, 1),\n",
    "    scatterpoints=1,        # Number of marker points in the legend entry\n",
    "    markerscale=2,          # Scale factor for legend markers (increase for bigger points)\n",
    "    fontsize=10             # Legend text size\n",
    ")\n",
    "kpca_f.align_ylabels([kpca_ax[:,0]])\n",
    "kpca_f.savefig(f'./Plots/{square_size}x{square_size}_{param}_kpca_{kernel}_{dataset}.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899f38ac",
   "metadata": {},
   "source": [
    "**Regression Experiments:**\n",
    "Based off what we found in the previous data exploration, it seems that non-linear methods will perform better. We will try to fit a RandomForest model to the UDPRS scores, and compare it to LASSO and OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ebd2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3364004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse UDPRS Scores\n",
    "merged_df= pd.read_csv(\"./MDVR-KCL-Features/MDVR-KCL-ReadText.csv\")\n",
    "for col in merged_df.columns:\n",
    "    if col != \"filename\":\n",
    "        merged_df[col] = (merged_df[col]- merged_df[col].mean())/ merged_df[col].std()\n",
    "merged_df_udprs = merged_df.copy()\n",
    "merged_df_udprs[\"II-5\"] = merged_df_udprs[\"filename\"].str.split(\"_\").str[-2]\n",
    "merged_df_udprs[\"III-18\"] = merged_df_udprs[\"filename\"].str.split(\"_\").str[-1]\n",
    "merged_df.set_index(\"filename\", inplace=True)\n",
    "merged_df_udprs.set_index(\"filename\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b58a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hopefully, LASSO can identify the collinear features (like ff_mean/median) and select the best one\n",
    "# It's not great to be honest, most weights go to 0 since a lot of samples are 0's in UDPRS\n",
    "# Makes the most accurate model just a trivial 0 vector solution\n",
    "LASSO_Model = Lasso(alpha = 5)\n",
    "X_train, X_test, y_train, y_test = train_test_split(merged_df, merged_df_udprs[[\"III-18\", \"II-5\"]], test_size=0.2, random_state=42)\n",
    "LASSO_Model.fit(X_train, y_train)\n",
    "y_pred = LASSO_Model.predict(X_test)\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"R^2 Score\", r2_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b7addb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Completely Non Linear method (reduces collinearity issues + features tend to fit towards non-linear space)\n",
    "RF_Regressor = RandomForestRegressor()\n",
    "X_train, X_test, y_train, y_test = train_test_split(merged_df, merged_df_udprs[[\"III-18\", \"II-5\"]], test_size=0.2, random_state=42)\n",
    "RF_Regressor.fit(X_train, y_train)\n",
    "y_pred = RF_Regressor.predict(X_test)\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"R^2 Score\", r2_score(y_test, y_pred))\n",
    "feature_importances = RF_Regressor.feature_importances_\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'feature': merged_df.columns,\n",
    "    'importance': feature_importances\n",
    "}).sort_values(by='importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d25a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_calculation import voice_embeddings\n",
    "embeddings_df_pd_sun = voice_embeddings.create_embedding_df(\"./MDVR-KCL/ReadText/PD-Sun/\")\n",
    "embeddings_df_hc_sun = voice_embeddings.create_embedding_df(\"./MDVR-KCL/ReadText/HC-Sun/\")\n",
    "embeddings_df_sun = pd.concat([embeddings_df_pd_sun, embeddings_df_hc_sun])\n",
    "embeddings_df_sun.to_csv(\"./MDVR-KCL-Features/sun_voice_embeddings.csv\", index=False)\n",
    "embeddings_df_sun = pd.read_csv(\"./MDVR-KCL-Features/sun_voice_embeddings.csv\", index_col=\"filename\")\n",
    "\n",
    "embeddings_df_pd_eng = voice_embeddings.create_embedding_df(\"./MDVR-KCL/ReadText/PD-Eng/\")\n",
    "embeddings_df_hc_eng = voice_embeddings.create_embedding_df(\"./MDVR-KCL/ReadText/HC-Eng/\")\n",
    "embeddings_df_eng = pd.concat([embeddings_df_pd_eng, embeddings_df_hc_eng])\n",
    "embeddings_df_eng.to_csv(\"./MDVR-KCL-Features/eng_voice_embeddings.csv\", index=False)\n",
    "embeddings_df_eng = pd.read_csv(\"./MDVR-KCL-Features/eng_voice_embeddings.csv\", index_col=\"filename\")\n",
    "\n",
    "embeddings_df = pd.concat([embeddings_df_sun, embeddings_df_eng])\n",
    "for df in [embeddings_df_sun, embeddings_df_eng, embeddings_df]:\n",
    "    df[\"II-5\"] = df.index.str.split(\"_\").str[-2]\n",
    "    df[\"III-18\"] = df.index.str.split(\"_\").str[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b2b067",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_Regressor = RandomForestRegressor()\n",
    "X_train, X_test, y_train, y_test = train_test_split(embeddings_df.iloc[:, :-2], embeddings_df.iloc[:, -2:], test_size=0.2, random_state=42)\n",
    "RF_Regressor.fit(X_train, y_train)\n",
    "y_pred = RF_Regressor.predict(X_test)\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"R^2 Score\", r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c7599c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
